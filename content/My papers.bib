@online{hassanThermoNeRFMultimodalNeural2024,
  title = {{{ThermoNeRF}}: {{Multimodal Neural Radiance Fields}} for {{Thermal Novel View Synthesis}}},
  shorttitle = {{{ThermoNeRF}}},
  author = {Hassan, Mariam and Forest, Florent and Fink, Olga and Mielle, Malcolm},
  date = {2024-03-18},
  eprint = {2403.12154},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2403.12154},
  urldate = {2024-04-08},
  abstract = {Thermal scene reconstruction exhibit great potential for applications across a broad spectrum of fields, including building energy consumption analysis and non-destructive testing. However, existing methods typically require dense scene measurements and often rely on RGB images for 3D geometry reconstruction, with thermal information being projected post-reconstruction. This two-step strategy, adopted due to the lack of texture in thermal images, can lead to disparities between the geometry and temperatures of the reconstructed objects and those of the actual scene. To address this challenge, we propose ThermoNeRF, a novel multimodal approach based on Neural Radiance Fields, capable of rendering new RGB and thermal views of a scene jointly. To overcome the lack of texture in thermal images, we use paired RGB and thermal images to learn scene density, while distinct networks estimate color and temperature information. Furthermore, we introduce ThermoScenes, a new dataset to palliate the lack of available RGB+thermal datasets for scene reconstruction. Experimental results validate that ThermoNeRF achieves accurate thermal image synthesis, with an average mean absolute error of 1.5\$\textasciicircum\textbackslash circ\$C, an improvement of over 50\% compared to using concatenated RGB+thermal data with Nerfacto, a state-of-the-art NeRF method.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/malcolm/Zotero/storage/3BSDB8X6/Hassan et al. - 2024 - ThermoNeRF Multimodal Neural Radiance Fields for Thermal Novel View Synthesis.pdf;/home/malcolm/Zotero/storage/TP2HVPTI/2403.html}
}

@article{mielleAutoCompleteGraphMerging2019,
  title = {The {{Auto-Complete Graph}}: {{Merging}} and {{Mutual Correction}} of {{Sensor}} and {{Prior Maps}} for {{SLAM}}},
  shorttitle = {The {{Auto-Complete Graph}}},
  author = {Mielle, Malcolm and Magnusson, Martin and Lilienthal, Achim J.},
  date = {2019-05-29},
  journaltitle = {Robotics},
  shortjournal = {Robotics},
  volume = {8},
  number = {2},
  pages = {40},
  issn = {2218-6581},
  doi = {10.3390/robotics8020040},
  url = {https://www.mdpi.com/2218-6581/8/2/40},
  urldate = {2024-04-08},
  abstract = {Simultaneous Localization And Mapping (SLAM) usually assumes the robot starts without knowledge of the environment. While prior information, such as emergency maps or layout maps, is often available, integration is not trivial since such maps are often out of date and have uncertainty in local scale. Integration of prior map information is further complicated by sensor noise, drift in the measurements, and incorrect scan registrations in the sensor map. We present the Auto-Complete Graph (ACG), a graph-based SLAM method merging elements of sensor and prior maps into one consistent representation. After optimizing the ACG, the sensor map’s errors are corrected thanks to the prior map, while the sensor map corrects the local scale inaccuracies in the prior map. We provide three datasets with associated prior maps: two recorded in campus environments, and one from a fireman training facility. Our method handled up to 40\% of noise in odometry, was robust to varying levels of details between the prior and the sensor map, and could correct local scale errors of the prior. In field tests with ACG, users indicated points of interest directly on the prior before exploration. We did not record failures in reaching them.},
  langid = {english},
  file = {/home/malcolm/Zotero/storage/VZPP9Z8A/Mielle et al. - 2019 - The Auto-Complete Graph Merging and Mutual Correction of Sensor and Prior Maps for SLAM.pdf}
}

@inproceedings{mielleComparativeAnalysisRadar2019,
  title = {A Comparative Analysis of Radar and Lidar Sensing for Localization and Mapping},
  booktitle = {2019 {{European Conference}} on {{Mobile Robots}} ({{ECMR}})},
  author = {Mielle, Malcolm and Magnusson, Martin and Lilienthal, Achim J.},
  date = {2019-09},
  pages = {1--6},
  publisher = {IEEE},
  location = {Prague, Czech Republic},
  doi = {10.1109/ECMR.2019.8870345},
  url = {https://ieeexplore.ieee.org/document/8870345/},
  urldate = {2024-04-08},
  eventtitle = {2019 {{European Conference}} on {{Mobile Robots}} ({{ECMR}})},
  isbn = {978-1-72813-605-9},
  file = {/home/malcolm/Zotero/storage/3VWJHS77/Mielle et al. - 2019 - A comparative analysis of radar and lidar sensing for localization and mapping.pdf}
}

@inproceedings{mielleMethodSegmentMaps2018a,
  title = {A {{Method}} to {{Segment Maps}} from {{Different Modalities Using Free Space Layout MAORIS}}: {{Map}} of {{Ripples Segmentation}}},
  shorttitle = {A {{Method}} to {{Segment Maps}} from {{Different Modalities Using Free Space Layout MAORIS}}},
  booktitle = {2018 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Mielle, Malcolm and Magnusson, Martin and Lilienthal, Achim J.},
  date = {2018-05},
  pages = {4993--4999},
  publisher = {IEEE},
  location = {Brisbane, QLD},
  doi = {10.1109/ICRA.2018.8461128},
  url = {https://ieeexplore.ieee.org/document/8461128/},
  urldate = {2024-04-10},
  eventtitle = {2018 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  isbn = {978-1-5386-3081-5},
  file = {/home/malcolm/Zotero/storage/KT3M6FPW/Mielle et al. - 2018 - A Method to Segment Maps from Different Modalities Using Free Space Layout MAORIS Map of Ripples Se.pdf}
}

@inproceedings{mielleSLAMAutocompleteCompleting2017a,
  title = {{{SLAM}} Auto-Complete: {{Completing}} a Robot Map Using an Emergency Map},
  shorttitle = {{{SLAM}} Auto-Complete},
  booktitle = {2017 {{IEEE International Symposium}} on {{Safety}}, {{Security}} and {{Rescue Robotics}} ({{SSRR}})},
  author = {Mielle, Malcolm and Magnusson, Martin and Andreasson, Henrik and Lilienthal, Achim J.},
  date = {2017-10},
  pages = {35--40},
  publisher = {IEEE},
  location = {Shanghai, China},
  doi = {10.1109/SSRR.2017.8088137},
  url = {http://ieeexplore.ieee.org/document/8088137/},
  urldate = {2024-04-10},
  eventtitle = {2017 {{IEEE International Symposium}} on {{Safety}}, {{Security}} and {{Rescue Robotics}} ({{SSRR}})},
  isbn = {978-1-5386-3923-8},
  file = {/home/malcolm/Zotero/storage/GXE7UZ3F/Mielle et al. - 2017 - SLAM auto-complete Completing a robot map using an emergency map.pdf}
}

@article{mielleURSIMUniqueRegions2019,
  title = {{{URSIM}}: {{Unique Regions}} for {{Sketch Map Interpretation}} and {{Matching}}},
  shorttitle = {{{URSIM}}},
  author = {Mielle, Malcolm and Magnusson, Martin and Lilienthal, Achim},
  date = {2019-06-05},
  journaltitle = {Robotics},
  shortjournal = {Robotics},
  volume = {8},
  number = {2},
  pages = {43},
  issn = {2218-6581},
  doi = {10.3390/robotics8020043},
  url = {https://www.mdpi.com/2218-6581/8/2/43},
  urldate = {2024-04-10},
  abstract = {We present a method for matching sketch maps to a corresponding metric map, with the aim of later using the sketch as an intuitive interface for human–robot interactions. While sketch maps are not metrically accurate and many details, which are deemed unnecessary, are omitted, they represent the topology of the environment well and are typically accurate at key locations. Thus, for sketch map interpretation and matching, one cannot only rely on metric information. Our matching method first finds the most distinguishable, or unique, regions of two maps. The topology of the maps, the positions of the unique regions, and the size of all regions are used to build region descriptors. Finally, a sequential graph matching algorithm uses the region descriptors to find correspondences between regions of the sketch and metric maps. Our method obtained higher accuracy than both a state-of-the-art matching method for inaccurate map matching, and our previous work on the subject. The state of the art was unable to match sketch maps while our method performed only 10\% worse than a human expert.},
  langid = {english},
  file = {/home/malcolm/Zotero/storage/L6IBFNH3/Mielle et al. - 2019 - URSIM Unique Regions for Sketch Map Interpretation and Matching.pdf}
}

@inproceedings{mielleUsingSketchmapsRobot2016a,
  title = {Using Sketch-Maps for Robot Navigation: {{Interpretation}} and Matching},
  shorttitle = {Using Sketch-Maps for Robot Navigation},
  booktitle = {2016 {{IEEE International Symposium}} on {{Safety}}, {{Security}}, and {{Rescue Robotics}} ({{SSRR}})},
  author = {Mielle, Malcolm and Magnusson, Martin and Lilienthal, Achim J.},
  date = {2016-10},
  pages = {252--257},
  publisher = {IEEE},
  location = {Lausanne, Switzerland},
  doi = {10.1109/SSRR.2016.7784307},
  url = {http://ieeexplore.ieee.org/document/7784307/},
  urldate = {2024-04-10},
  eventtitle = {2016 {{IEEE International Symposium}} on {{Safety}}, {{Security}}, and {{Rescue Robotics}} ({{SSRR}})},
  isbn = {978-1-5090-4349-1}
}

@inproceedings{panchettiTEAMParameterFreeAlgorithm2023,
  title = {{{TEAM}}: {{A Parameter-Free Algorithm}} to {{Teach Collaborative Robots Motions}} from {{User Demonstrations}}:},
  shorttitle = {{{TEAM}}},
  booktitle = {Proceedings of the 20th {{International Conference}} on {{Informatics}} in {{Control}}, {{Automation}} and {{Robotics}}},
  author = {Panchetti, Lorenzo and Zheng, Jianhao and Bouri, Mohamed and Mielle, Malcolm},
  date = {2023},
  pages = {570--577},
  publisher = {{SCITEPRESS - Science and Technology Publications}},
  location = {Rome, Italy},
  doi = {10.5220/0012159700003543},
  url = {https://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0012159700003543},
  urldate = {2024-04-10},
  eventtitle = {20th {{International Conference}} on {{Informatics}} in {{Control}}, {{Automation}} and {{Robotics}}},
  isbn = {978-989-758-670-5},
  file = {/home/malcolm/Zotero/storage/IV5LKCU5/Panchetti et al. - 2023 - TEAM A Parameter-Free Algorithm to Teach Collaborative Robots Motions from User Demonstrations.pdf}
}

@inproceedings{sun3QFPEfficientNeural2024,
  title = {{{3QFP}}: {{Efficient}} Neural Implicit Surface Reconstruction Using {{Tri-Quadtrees}} and {{Fourier}} Feature {{Positional}} Encoding},
  shorttitle = {{{3QFP}}},
  booktitle = {2024 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Sun, Shuo and Mielle, Malcolm and Lilienthal, Achim J. and Magnusson, Martin},
  date = {2024-05-13},
  eprint = {2401.07164},
  eprinttype = {arXiv},
  eprintclass = {cs},
  publisher = {IEEE},
  location = {Yokohama, Japan},
  url = {http://arxiv.org/abs/2401.07164},
  urldate = {2024-04-08},
  abstract = {Neural implicit surface representations are currently receiving a lot of interest as a means to achieve high-fidelity surface reconstruction at a low memory cost, compared to traditional explicit representations.However, state-of-the-art methods still struggle with excessive memory usage and non-smooth surfaces. This is particularly problematic in large-scale applications with sparse inputs, as is common in robotics use cases. To address these issues, we first introduce a sparse structure, \textbackslash emph\{tri-quadtrees\}, which represents the environment using learnable features stored in three planar quadtree projections. Secondly, we concatenate the learnable features with a Fourier feature positional encoding. The combined features are then decoded into signed distance values through a small multi-layer perceptron. We demonstrate that this approach facilitates smoother reconstruction with a higher completion ratio with fewer holes. Compared to two recent baselines, one implicit and one explicit, our approach requires only 10\textbackslash\%--50\textbackslash\% as much memory, while achieving competitive quality.},
  eventtitle = {2024 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  keywords = {Computer Science - Robotics},
  file = {/home/malcolm/Zotero/storage/5V5U6TE2/Sun et al. - 2024 - 3QFP Efficient neural implicit surface reconstruction using Tri-Quadtrees and Fourier feature Posit.pdf;/home/malcolm/Zotero/storage/48IGUT5H/2401.html}
}

@inproceedings{sunHighFidelitySLAMUsing2024,
  title = {High-{{Fidelity SLAM Using Gaussian Splatting}} with {{Rendering-Guided Densification}} and {{Regularized Optimization}}},
  booktitle = {2024 {{IEEE International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Sun, Shuo and Mielle, Malcolm and Lilienthal, Achim J. and Magnusson, Martin},
  date = {2024-10-14},
  eprint = {2403.12535},
  eprinttype = {arXiv},
  eprintclass = {cs},
  publisher = {IEEE},
  location = {Abu Dhabi, UAE},
  url = {http://arxiv.org/abs/2403.12535},
  urldate = {2024-04-08},
  abstract = {We propose a dense RGBD SLAM system based on 3D Gaussian Splatting that provides metrically accurate pose tracking and visually realistic reconstruction. To this end, we first propose a Gaussian densification strategy based on the rendering loss to map unobserved areas and refine reobserved areas. Second, we introduce extra regularization parameters to alleviate the forgetting problem in the continuous mapping problem, where parameters tend to overfit the latest frame and result in decreasing rendering quality for previous frames. Both mapping and tracking are performed with Gaussian parameters by minimizing re-rendering loss in a differentiable way. Compared to recent neural and concurrently developed gaussian splatting RGBD SLAM baselines, our method achieves state-of-the-art results on the synthetic dataset Replica and competitive results on the real-world dataset TUM.},
  eventtitle = {2024 {{IEEE International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Robotics},
  file = {/home/malcolm/Zotero/storage/QYQ3ENWN/Sun et al. - 2024 - High-Fidelity SLAM Using Gaussian Splatting with Rendering-Guided Densification and Regularized Opti.pdf;/home/malcolm/Zotero/storage/98A3I5XC/2403.html}
}
